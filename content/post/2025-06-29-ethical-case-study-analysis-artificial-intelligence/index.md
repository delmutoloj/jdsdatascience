---
title: 'Ethical Case Study Analysis: Artificial Intelligence'
author: James Del Mutolo
date: '2025-06-29'
slug: ethical-case-study-analysis-artificial-intelligence
categories: []
tags: []
---
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In recent years, advancements in artificial intelligence have completely changed how digital content is produced. “Generative Artificial Intelligence (GenAI), a subfield of artificial intelligence, refers to models capable of generating data such as text, images, and audio, based on learned statistical patterns… While these technologies can bring about innovative changes in teaching and learning practices, they also raise important issues that educators, policymakers, and students must navigate.” (Perkins et al., 2024, p. 2). This case study will address the ethics of using GenAI, and the potential implications of using it in educational and professional settings. The practice of critical thinking is essential in evaluating not only the benefits of GenAI, but also the issues presented that relate to academic integrity, fair use, and bias in the generative models that are used.

# Ethical Implications

### Academic Integrity

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In their article Teaching AI Ethics, Leon Furze states that “[m]uch of the narrative around models like OpenAI’s ChatGPT has centered on students using it to cheat on assignments. But I’ve already been working with schools this year who are much more interested in the potential of these technologies to help rather than hinder education.” (Furze, 2023). While concerns about academic honesty are valid, it is also important to explore how GenAI can be used to support learning, creativity, as well as to develop digital literacy. Perkins et al. propose “a structured approach for [higher education institutions] to integrate GenAI into their assessment strategies, with each level specifying the extent of allowed GenAI use and student responsibility.” (Perkins et al., 2024, p. 7). This “AI Assessment Scale” defines five levels of GenAI use with level one being no use of AI, and level five allowing full use of AI without disclosing which content is AI generated. The levels in between are AI-assisted idea generation, AI-assisted editing, and AI task evaluation with human evaluation. Utilizing this scale to define the requirements of an assignment, in conjunction with submitting an AI disclosure form if applicable, would allow educators and students to maintain transparency, while also promoting ethical use of GenAI tools.

### Fair Use

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A large concern surrounding the use of GenAI tools is their reliance on datasets that often contain copyrighted material, raising questions about fair use and intellectual property rights. “Copyright issues have been particularly prevalent in AI image generation. AI image generators like Stable Diffusion, DALL-E 2, and Midjourney are trained on images ‘scraped’ from the internet… This has resulted in artist’s ‘styles’ being used in AI image generation without their permission. Many artists believe that this infringes their intellectual property rights, and is an ethical issue.” (Furze, 2023). This issue also applies to AI-generated text. The legal system has yet to clearly define the boundaries of fair use in the context of AI-generated content. This remains a grey area within copyright law and intellectual property rights, one that will require further litigation and policy development to establish clearer guidelines and protections for all stakeholders.

### Bias

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The final issue to be discussed pertains to the representation bias that occurs when training both predictive and GenAI models. “For example, police in the US have used systems for ‘predictive policing’ which use algorithms to predict people likely to commit crimes. These algorithms disproportionately target poor, Black, and Latinx communities, reinforcing existing systemic biases.” (Furze, 2023). These biases also apply to GenAI models as “[i]ndiscriminately ‘scraping’ the internet lets in the bad along with the good, meaning that the dataset can contain racist, sexist, ableist, and otherwise discriminatory language.” (Furze, 2023). This is because “the online community underrepresents marginalised groups, and overrepresents others.” (Furze, 2023). Developers and institutions could make an effort to reduce these harms by adopting more intentional data collection practices when developing their AI models.

# Conclusion

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GenAI is a very powerful tool that has the potential to bring meaningful advancements to educational and professional practices. However, its use also raises many ethical concerns such as academic integrity, fair use, and bias. Thinking critically about these multifaceted issues allows us to understand not only the benefits and limitations of GenAI, but also the responsibilities that come with its use.

# References

Furze, L. (2023, January 26). Teaching AI Ethics. Leon Furze. https://leonfurze.com/2023/01/26/teaching-ai-ethics/#human-labour

Perkins, M., Furze, L., Roe, J., & MacVaugh, J. (2024, 4 19). The AI Assessment Scale (AIAS): A Framework For Ethical Integration Of Generative AI In Educational Assessment. JUTLP, 21(6). https://arxiv.org/pdf/2312.07086
